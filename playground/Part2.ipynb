{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15763539",
   "metadata": {},
   "source": [
    "## Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c823a6",
   "metadata": {},
   "source": [
    "Next, take one of the samples from training dataset and use PINN [3] for estimating the value of\n",
    "G. Report the CPU/GPU time taken. You may use equation 4 for computing the residual loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7510c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fa6d09",
   "metadata": {},
   "source": [
    "### Device and seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a4fcc0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = tf.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f\"Device used: {device}\")\n",
    "np.random.seed(seed=1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3b08e3",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e7b6962",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "relative_csv_path = \"./../src/data/raw/Dataset.csv\"\n",
    "split_ratio = 0.2\n",
    "\n",
    "# Load different temperatures samples \n",
    "fields = ['T1', 'T2', 'T3', 'T4' ,'T5', 'T6' ,'T7', 'T8' ,'T9']\n",
    "df_T = pd.read_csv(relative_csv_path, skipinitialspace=True, usecols=fields)\n",
    "X_train, X_test = train_test_split(df_T, test_size = split_ratio)\n",
    "\n",
    "# Load different G values \n",
    "fields = ['G']\n",
    "df_G = pd.read_csv(relative_csv_path, skipinitialspace=True, usecols=fields)\n",
    "Y_train, Y_test = train_test_split(df_G, test_size = split_ratio)\n",
    "\n",
    "# Convert into numpy arrays\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "Y_test = Y_test.to_numpy()\n",
    "Y_train = Y_train.to_numpy()\n",
    "Y = df_T.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7de3ff6",
   "metadata": {},
   "source": [
    "## Data sample \n",
    "$$\n",
    "X = [T1,T2,T3,T4,T5,T6,T7,T8] \\rightarrow G1\n",
    "$$\n",
    "## Transform data to this nomenclature:\n",
    "\n",
    " $$\n",
    "     [T_{11}, X_{1}] \\rightarrow G_1\\\\ \n",
    "     [T_{12}, X_{2}] \\rightarrow G_1\\\\\n",
    "     [T_{13}, X_{3}] \\rightarrow G_1\\\\\n",
    "     [T_{14}, X_{4}] \\rightarrow G_1\\\\\n",
    "     [T_{15}, X_{5}] \\rightarrow G_1\\\\\n",
    "     [T_{16}, X_{6}] \\rightarrow G_1\\\\\n",
    "     [T_{17}, X_{7}] \\rightarrow G_1\\\\\n",
    "     [T_{18}, X_{8}] \\rightarrow G_1\\\\\n",
    "     [T_{21}, X_{1}] \\rightarrow G_2\\\\ \n",
    "     [T_{22}, X_{2}] \\rightarrow G_2\\\\\n",
    "     [T_{23}, X_{3}] \\rightarrow G_2\\\\\n",
    "     [T_{24}, X_{4}] \\rightarrow G_2\\\\\n",
    "     [T_{25}, X_{5}] \\rightarrow G_2\\\\\n",
    "     [T_{26}, X_{6}] \\rightarrow G_2\\\\\n",
    "     [T_{27}, X_{7}] \\rightarrow G_2\\\\\n",
    "     [T_{29}, X_{8}] \\rightarrow G_2\n",
    "     $$\n",
    "\n",
    "<!-- \n",
    "T2,T3,T4,T5,T6,T7,T8] \\rightarrow G1\n",
    "$$\n",
    "\n",
    "$\n",
    "X = [\n",
    "      [T_1, X_1] [G \n",
    "$ -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7bff3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_to_PINN(X_input, Y_output):\n",
    "    \"\"\"\n",
    "    Function to transform the input data to [x1, x2, ... xN] and [T1, T2, ... Tn].\n",
    "\n",
    "    Parameters:\n",
    "       X_input (narray): Input array.\n",
    "       Y_output (narray): Output array.\n",
    "\n",
    "\"\"\"       \n",
    "    # Split T into a vector\n",
    "    T_col = X_input.reshape(-1,1)\n",
    "    N_samples = T_col.shape[0]\n",
    "    \n",
    "    # Create a X_col vector\n",
    "    X_col = np.zeros_like(T_col)\n",
    "\n",
    "    # Create a G_col vector\n",
    "    G_col = np.zeros_like(T_col)\n",
    "\n",
    "    # Fill G and X\n",
    "    for n in range(T_col.shape[0]):\n",
    "        X_col[n] = n % 9 / 10 \n",
    "        G_col[n] = Y_output[n // 9]\n",
    "    \n",
    "    return X_col, T_col, G_col\n",
    "\n",
    "X, T, G = process_data_to_PINN(X_train, Y_train)\n",
    "\n",
    "# Check outputs\n",
    "assert(X.shape[0] == T.shape[0] == G.shape[0])\n",
    "rand_acces = np.random.randint(0,high = T.shape[0], size=1)\n",
    "assert(X[rand_acces] == X[rand_acces[0] + 9])\n",
    "assert(G[rand_acces] != G[rand_acces[0] + 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc81b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.config.experimental.enable_tensor_float_32_execution(False)\n",
    "#os.environ[‘TF_ENABLE_AUTO_MIXED_PRECISION’] = ‘1’\n",
    "\n",
    "# Initalization of Network\n",
    "def hyper_initial(size):\n",
    "    \"\"\"\n",
    "    Initilizes the layer weights according to Xavier procedure. \n",
    "    \n",
    "    Parameters:\n",
    "       size (integer): Input size.\n",
    "    \n",
    "    \"\"\"\n",
    "    in_dim = size[0]\n",
    "    out_dim = size[1]\n",
    "    std = np.sqrt(2.0/(in_dim + out_dim))\n",
    "    return tf.Variable(tf.random.truncated_normal(shape=size, stddev = std))\n",
    "\n",
    "# Neural Network \n",
    "def DNN(X, W, b):\n",
    "    A = X\n",
    "    L = len(W)\n",
    "    for i in range(L-1):\n",
    "        A = tf.tanh(tf.add(tf.matmul(A, W[i]), b[i]))\n",
    "    Y = tf.add(tf.matmul(A, W[-1]), b[-1])\n",
    "    return Y\n",
    "\n",
    "def train_vars(W, b):\n",
    "    return W + b\n",
    "\n",
    "def net_u(x, t, w, b):\n",
    "    u = DNN(tf.concat([x,t],1), w, b)\n",
    "    return u\n",
    "\n",
    "\n",
    "#@tf.function(jit_compile=True)\n",
    "@tf.function\n",
    "def net_f(x,t,W, b, nu):\n",
    "    with tf.GradientTape(persistent=True) as tape1:\n",
    "        tape1.watch([x, t])\n",
    "        with tf.GradientTape(persistent=True) as tape2:\n",
    "            tape2.watch([x, t])\n",
    "            u=net_u(x,t, W, b)\n",
    "        u_t = tape2.gradient(u, t)\n",
    "        u_x = tape2.gradient(u, x)\n",
    "    u_xx = tape1.gradient(u_x, x)  \n",
    "    del tape1\n",
    "    f = u_t + u*u_x - nu*u_xx\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "#@tf.function(jit_compile=True)\n",
    "@tf.function\n",
    "def train_step(W, b, X_u_train_tf, u_train_tf, X_f_train_tf, opt, nu):\n",
    "    x_u = X_u_train_tf[:,0:1]\n",
    "    t_u = X_u_train_tf[:,1:2]\n",
    "    x_f = X_f_train_tf[:,0:1]\n",
    "    t_f = X_f_train_tf[:,1:2]\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch([W,b])\n",
    "        u_nn = net_u(x_u, t_u, W, b) \n",
    "        f_nn = net_f(x_f,t_f, W, b, nu)\n",
    "        loss =  tf.reduce_mean(tf.square(u_nn - u_train_tf)) + tf.reduce_mean(tf.square(f_nn)) \n",
    "    grads = tape.gradient(loss, train_vars(W,b))\n",
    "    opt.apply_gradients(zip(grads, train_vars(W,b)))\n",
    "    return loss\n",
    "\n",
    "\n",
    "    \n",
    "nu = 0.01/np.pi\n",
    "noise = 0.0        \n",
    "N_u = 100\n",
    "N_f = 10000\n",
    "Nmax=40000\n",
    "\n",
    "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
    "L = len(layers)\n",
    "W = [hyper_initial([layers[l-1], layers[l]]) for l in range(1, L)] \n",
    "b = [tf.Variable(tf.zeros([1, layers[l]])) for l in range(1, L)] \n",
    "\n",
    "data = scipy.io.loadmat('./Data/burgers_shock.mat')\n",
    "\n",
    "t = data['t'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = np.real(data['usol']).T\n",
    "X, T = np.meshgrid(x,t)\n",
    "X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "u_star = Exact.flatten()[:,None]              \n",
    "# Doman bounds\n",
    "lb = X_star.min(0)\n",
    "ub = X_star.max(0)    \n",
    "xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T))\n",
    "uu1 = Exact[0:1,:].T\n",
    "xx2 = np.hstack((X[:,0:1], T[:,0:1]))\n",
    "uu2 = Exact[:,0:1]\n",
    "xx3 = np.hstack((X[:,-1:], T[:,-1:]))\n",
    "uu3 = Exact[:,-1:]\n",
    "\n",
    "X_u_train = np.vstack([xx1, xx2, xx3])\n",
    "X_f_train = lb + (ub-lb)*lhs(2, N_f)\n",
    "X_f_train = np.vstack((X_f_train, X_u_train))\n",
    "u_train = np.vstack([uu1, uu2, uu3])\n",
    "\n",
    "idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
    "\n",
    "X_u_train = X_u_train[idx, :]\n",
    "u_train = u_train[idx,:]\n",
    "\n",
    "X_u_train_tf = tf.convert_to_tensor(X_u_train, dtype=tf.float32)\n",
    "u_train_tf =   tf.convert_to_tensor(u_train, dtype=tf.float32)\n",
    "X_f_train_tf = tf.convert_to_tensor(X_f_train, dtype=tf.float32)\n",
    "\n",
    "lr = 1e-3\n",
    "optimizer = tf.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "start_time = time.time()\n",
    "n=0\n",
    "loss = []\n",
    "while n <= Nmax:\n",
    "    loss_= train_step(W, b, X_u_train_tf, u_train_tf, X_f_train_tf, optimizer, nu)\n",
    "    loss.append(loss_)    \n",
    "    print(f\"Iteration is: {n} and loss is: {loss_}\")\n",
    "    n+=1\n",
    "\n",
    "elapsed = time.time() - start_time                \n",
    "print('Training time: %.4f' % (elapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d5bc21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe5892",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
