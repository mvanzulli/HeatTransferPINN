{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15763539",
   "metadata": {},
   "source": [
    "## Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c823a6",
   "metadata": {},
   "source": [
    "Next, take one of the samples from training dataset and use PINN [3] for estimating the value of\n",
    "G. Report the CPU/GPU time taken. You may use equation 4 for computing the residual loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7510c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fa6d09",
   "metadata": {},
   "source": [
    "### Device and seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a4fcc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = tf.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f\"Device used: {device}\")\n",
    "# np.random.seed(seed=1234)\n",
    "seed=5\n",
    "tf.random.set_seed(seed)\n",
    "tf.config.list_physical_devices('GPU')\n",
    "picked = tf.random.uniform([1],0,400,dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3b08e3",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0e7b6962",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "relative_csv_path = \"./../src/data/raw/Dataset.csv\"\n",
    "split_ratio = 0.2\n",
    "\n",
    "# Load different temperatures samples \n",
    "fields = ['T1', 'T2', 'T3', 'T4' ,'T5', 'T6' ,'T7', 'T8' ,'T9']\n",
    "df_T = pd.read_csv(relative_csv_path, skipinitialspace=True, usecols=fields)\n",
    "T_train=df_T.to_numpy()[picked,]\n",
    "\n",
    "T_inf = 27 + 273 #in K\n",
    "T_b = 127 + 273 #in K\n",
    "Theta = np.multiply(np.add(T, [-T_inf]), [1/(T_b - T_inf)])\n",
    "Theta = Theta.T\n",
    "\n",
    "# Load different G values \n",
    "fields = ['G']\n",
    "df_G = pd.read_csv(relative_csv_path, skipinitialspace=True, usecols=fields)\n",
    "G_test = df_G.to_numpy()[picked,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeea8c9",
   "metadata": {},
   "source": [
    "## $X^*_T$ and  $X^*_F$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b1cbc826",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nu = Theta.shape[0]\n",
    "Nf = 50\n",
    "X_T = np.linspace(0,1,Nu).reshape(-1,1)\n",
    "X_F = np.linspace(0,1,Nf).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24faf7f",
   "metadata": {},
   "source": [
    "## Transforming into TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b28856d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta_tf = tf.convert_to_tensor(Theta, dtype=tf.float32)\n",
    "X_T_tf = tf.convert_to_tensor(X_T, dtype=tf.float32)\n",
    "X_F_tf = tf.convert_to_tensor(X_F, dtype=tf.float32)\n",
    "x0 = X_T_tf[0] # X* = 0 para la boundary condition\n",
    "x1 = X_T_tf[-1] # X* = 1 para la boundary condition\n",
    "Theta_tf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bfc81b4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [117], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m W \u001b[38;5;241m=\u001b[39m [hyper_initial([layers[l\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], layers[l]]) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, L)] \n\u001b[1;32m     79\u001b[0m b \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mVariable(tf\u001b[38;5;241m.\u001b[39mzeros([\u001b[38;5;241m1\u001b[39m, layers[l]])) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, L)] \n\u001b[0;32m---> 81\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mloadmat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Data/burgers_shock.mat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     83\u001b[0m t \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten()[:,\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m     84\u001b[0m x \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten()[:,\u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "tf.config.experimental.enable_tensor_float_32_execution(False)\n",
    "#os.environ[‘TF_ENABLE_AUTO_MIXED_PRECISION’] = ‘1’\n",
    "\n",
    "# Initalization of Network\n",
    "def hyper_initial(size):\n",
    "    \"\"\"\n",
    "    Initilizes the layer weights according to Xavier procedure. \n",
    "    \n",
    "    Parameters:\n",
    "       size (integer): Input size.\n",
    "    \n",
    "    \"\"\"\n",
    "    in_dim = size[0]\n",
    "    out_dim = size[1]\n",
    "    std = np.sqrt(2.0/(in_dim + out_dim))\n",
    "    return tf.Variable(tf.random.truncated_normal(shape=size, stddev = std))\n",
    "\n",
    "# Neural Network \n",
    "def DNN(X, W, b):\n",
    "    A = X\n",
    "    L = len(W)\n",
    "    for i in range(L-1):\n",
    "        A = tf.tanh(tf.add(tf.matmul(A, W[i]), b[i]))\n",
    "    Y = tf.add(tf.matmul(A, W[-1]), b[-1])\n",
    "    return Y\n",
    "\n",
    "def train_vars(W, b):\n",
    "    return W + b\n",
    "\n",
    "# def net_u(x, t, w, b):\n",
    "#     u = DNN(tf.concat([x,t],1), w, b)\n",
    "#     return u\n",
    "\n",
    "def net_u(x, w, b):\n",
    "    out_net_u = DNN(x, w, b)\n",
    "    N, G, eg, ec, theta = out_net_u[0], out_net_u[1], out_net_u[2], out_net_u[3], out_net_u[4] # probar sacar derechito\n",
    "    return N, G, eg, ec, theta\n",
    "\n",
    "\n",
    "#@tf.function(jit_compile=True)\n",
    "# @tf.function\n",
    "# def net_f(x,t,W, b, nu):\n",
    "#     with tf.GradientTape(persistent=True) as tape1:\n",
    "#         tape1.watch([x, t])\n",
    "#         with tf.GradientTape(persistent=True) as tape2:\n",
    "#             tape2.watch([x, t])\n",
    "#             u=net_u(x,t, W, b)\n",
    "#         u_t = tape2.gradient(u, t)\n",
    "#         u_x = tape2.gradient(u, x)\n",
    "#     u_xx = tape1.gradient(u_x, x)  \n",
    "#     del tape1\n",
    "#     f = u_t + u*u_x - nu*u_xx\n",
    "#     return f\n",
    "\n",
    "@tf.function\n",
    "def net_f(x, W, b):\n",
    "    with tf.GradientTape(persistent=True) as tape1:\n",
    "        tape1.watch(x)\n",
    "        with tf.GradientTape(persistent=True) as tape2:\n",
    "            tape2.watch(x)\n",
    "            N, G, eg, ec, theta = net_u(x, W, b)\n",
    "            theta_x = tape2.gradient(theta, x)\n",
    "            aux = (1 + ec * theta) * theta_x      \n",
    "    aux_x = tape1.gradient(aux, x)  \n",
    "    del tape1\n",
    "    f = aux_x - N**2*theta + N**2*G*(1 + eg*theta) \n",
    "    return f\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def net_bc(x, W, b):\n",
    "    with tf.GradientTape(persistent=True) as tape3:\n",
    "        tape3.watch(x)\n",
    "        _, _, _, _, theta = net_u(x, W, b)\n",
    "        theta_x = tape3.gradient(theta, x)\n",
    "    del tape3\n",
    "    f = theta_x \n",
    "    return f\n",
    "\n",
    "\n",
    "#@tf.function(jit_compile=True)\n",
    "@tf.function\n",
    "\n",
    "Theta_tf = tf.convert_to_tensor(Theta, dtype=tf.float32)\n",
    "X_T_tf = tf.convert_to_tensor(X_T, dtype=tf.float32)\n",
    "X_F_tf = tf.convert_to_tensor(X_F, dtype=tf.float32)\n",
    "x0=X_T_tf[0] # X* = 0 para la boundary condition\n",
    "x1=X_T_tf[-1] # X* = 1 para la boundary condition\n",
    "\n",
    "\n",
    "def train_step(W, b, X_T_tf, Theta_tf, X_F_tf, x1, opt):\n",
    "    x_u = X_T_tf[:,0:1] \n",
    "    x_f = X_F_tf[:,0:1]\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch([W,b])\n",
    "        N_nn, G_nn, eg_nn, ec_nn, theta_nn = net_u(X_T_tf, W, b) \n",
    "        f_nn = net_f(X_F_tf, W, b)\n",
    "        bc_nn = net_bc(x1, W, b)\n",
    "        loss_T = tf.reduce_mean(tf.square(theta_nn - Theta_tf)) \n",
    "        loss_f = tf.reduce_mean(tf.square(f_nn))\n",
    "        loss_bc = tf.reduce_mean(tf.square(bc_nn))\n",
    "        loss =  loss_T + loss_f + loss_bc  \n",
    "    grads = tape.gradient(loss, train_vars(W,b))\n",
    "    opt.apply_gradients(zip(grads, train_vars(W,b)))\n",
    "    return loss\n",
    "\n",
    "\n",
    "    \n",
    "# nu = 0.01/np.pi\n",
    "# noise = 0.0        \n",
    "# N_u = 100\n",
    "# N_f = 10000\n",
    "# Nmax=40000\n",
    "\n",
    "# layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
    "# L = len(layers)\n",
    "# W = [hyper_initial([layers[l-1], layers[l]]) for l in range(1, L)] \n",
    "# b = [tf.Variable(tf.zeros([1, layers[l]])) for l in range(1, L)] \n",
    "\n",
    "# data = scipy.io.loadmat('./Data/burgers_shock.mat')\n",
    "\n",
    "# t = data['t'].flatten()[:,None]\n",
    "# x = data['x'].flatten()[:,None]\n",
    "# Exact = np.real(data['usol']).T\n",
    "# X, T = np.meshgrid(x,t)\n",
    "# X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "# u_star = Exact.flatten()[:,None]              \n",
    "# # Doman bounds\n",
    "# lb = X_star.min(0)\n",
    "# ub = X_star.max(0)    \n",
    "# xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T))\n",
    "# uu1 = Exact[0:1,:].T\n",
    "# xx2 = np.hstack((X[:,0:1], T[:,0:1]))\n",
    "# uu2 = Exact[:,0:1]\n",
    "# xx3 = np.hstack((X[:,-1:], T[:,-1:]))\n",
    "# uu3 = Exact[:,-1:]\n",
    "\n",
    "# X_u_train = np.vstack([xx1, xx2, xx3])\n",
    "# X_f_train = lb + (ub-lb)*lhs(2, N_f)\n",
    "# X_f_train = np.vstack((X_f_train, X_u_train))\n",
    "# u_train = np.vstack([uu1, uu2, uu3])\n",
    "\n",
    "# idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
    "\n",
    "# X_u_train = X_u_train[idx, :]\n",
    "# u_train = u_train[idx,:]\n",
    "\n",
    "# X_u_train_tf = tf.convert_to_tensor(X_u_train, dtype=tf.float32)\n",
    "# u_train_tf =   tf.convert_to_tensor(u_train, dtype=tf.float32)\n",
    "# X_f_train_tf = tf.convert_to_tensor(X_f_train, dtype=tf.float32)\n",
    "\n",
    "# lr = 1e-3\n",
    "# optimizer = tf.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "# start_time = time.time()\n",
    "# n=0\n",
    "# loss = []\n",
    "# while n <= Nmax:\n",
    "#     loss_= train_step(W, b, X_u_train_tf, u_train_tf, X_f_train_tf, optimizer, nu)\n",
    "#     loss.append(loss_)    \n",
    "#     print(f\"Iteration is: {n} and loss is: {loss_}\")\n",
    "#     n+=1\n",
    "\n",
    "# elapsed = time.time() - start_time                \n",
    "# print('Training time: %.4f' % (elapsed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d5bc21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe5892",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
